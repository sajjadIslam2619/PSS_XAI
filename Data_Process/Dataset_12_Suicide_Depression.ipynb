{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86a2cc37",
   "metadata": {},
   "source": [
    "Title: Deep Learning for Suicide and Depression Identification with Unsupervised Label Correction\n",
    "\n",
    "Link: https://github.com/ayaanzhaque/SDCNL/blob/main/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85013f9e",
   "metadata": {},
   "source": [
    "Dataset description: The studyâ€™s primary dataset was collected from Reddit posts in r/Depression and r/SuicideWatch, containing 1,895 posts labeled according to subreddit membership. To validate the label correction method, the authors also used the Reddit C-SSRS dataset (500 posts labeled by psychologists using the Columbia Suicide Severity Rating Scale) and the IMDB movie review dataset (50,000 reviews for sentiment classification). Additionally, posts from r/CasualConversation were used alongside r/SuicideWatch to construct a comparison dataset for suicide vs healthy classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "292bd9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 915 rows to d:\\Sajjad-Workspace\\PSS_XAI\\Data_Process\\Data_Warehouse\\depression_dataset_2.csv\n",
      "Saved 980 rows to d:\\Sajjad-Workspace\\PSS_XAI\\Data_Process\\Data_Warehouse\\suicide_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ========= CONFIG =========\n",
    "project_dir = Path.cwd()   # current working directory\n",
    "source_dir = project_dir / \"Data_Lake\" / \"Dataset_12\"\n",
    "warehouse_dir = project_dir / \"Data_Warehouse\"\n",
    "warehouse_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========= LOAD DATA =========\n",
    "# Replace with your actual file name inside Dataset_12\n",
    "df = pd.read_csv(source_dir / \"combined-set.csv\")\n",
    "\n",
    "# ========= MAP LABELS =========\n",
    "def map_label(row):\n",
    "    return \"suicide\" if row[\"is_suicide\"] == 1 else \"depression\"\n",
    "\n",
    "def map_subsource(row):\n",
    "    return \"r/SuicideWatch\" if row[\"is_suicide\"] == 1 else \"r/Depression\"\n",
    "\n",
    "df[\"label\"] = df.apply(map_label, axis=1)\n",
    "df[\"sub-source\"] = df.apply(map_subsource, axis=1)\n",
    "df[\"source\"] = \"Dataset_12\"\n",
    "df[\"text\"] = df[\"selftext\"]\n",
    "\n",
    "# Keep only required columns\n",
    "df_final = df[[\"text\", \"label\", \"sub-source\", \"source\"]]\n",
    "\n",
    "# ========= FUNCTION: get unique filename =========\n",
    "def get_unique_path(base_dir: Path, base_name: str) -> Path:\n",
    "    \"\"\"Return a unique path by adding _2, _3, etc. if needed.\"\"\"\n",
    "    out_path = base_dir / base_name\n",
    "    if not out_path.exists():\n",
    "        return out_path\n",
    "    stem, ext = base_name.rsplit(\".\", 1)\n",
    "    i = 2\n",
    "    while True:\n",
    "        new_name = f\"{stem}_{i}.{ext}\"\n",
    "        out_path = base_dir / new_name\n",
    "        if not out_path.exists():\n",
    "            return out_path\n",
    "        i += 1\n",
    "\n",
    "# ========= SAVE SEPARATE FILES =========\n",
    "for class_name in df_final[\"label\"].unique():\n",
    "    subset = df_final[df_final[\"label\"] == class_name]\n",
    "    out_path = get_unique_path(warehouse_dir, f\"{class_name}_dataset.csv\")\n",
    "    subset.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Saved {len(subset)} rows to {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312_xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
