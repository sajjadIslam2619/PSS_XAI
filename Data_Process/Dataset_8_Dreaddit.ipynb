{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9490d92",
   "metadata": {},
   "source": [
    "Title: Dreaddit: A Reddit Dataset for Stress Analysis in Social Media\n",
    "\n",
    "Link: Direct download link avaialbe in the paper's 1st page footnote. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29424a8",
   "metadata": {},
   "source": [
    "Dataset description: The Dreaddit dataset consists of 187,444 Reddit posts collected from ten subreddits across five domains (abuse, anxiety, financial, PTSD, and social/relationships). A subset of 3,553 text segments was annotated through Amazon Mechanical Turk for stress classification, with labels indicating stressful or non-stressful content. Unlike short microblogs, Dreaddit provides long-form, multi-domain narratives, enabling deeper analysis of how stress is expressed in online communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c906ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 414 rows to d:\\Sajjad-Workspace\\PSS_XAI\\Data_Process\\Data_Warehouse\\ptsd_dataset_2.csv\n",
      "Saved 1027 rows to d:\\Sajjad-Workspace\\PSS_XAI\\Data_Process\\Data_Warehouse\\stress_dataset_2.csv\n",
      "Saved 416 rows to d:\\Sajjad-Workspace\\PSS_XAI\\Data_Process\\Data_Warehouse\\anxiety_dataset_2.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ========= CONFIG =========\n",
    "project_dir = Path.cwd()\n",
    "source_dir = project_dir / \"Data_Lake\" / \"Dataset_8\"\n",
    "warehouse_dir = project_dir / \"Data_Warehouse\"\n",
    "warehouse_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========= LOAD DATA =========\n",
    "train_df = pd.read_csv(source_dir / \"dreaddit-train.csv\")\n",
    "test_df = pd.read_csv(source_dir / \"dreaddit-test.csv\")\n",
    "\n",
    "# Combine train and test\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# Keep only stress-labeled rows (label == 1)\n",
    "df = df[df[\"label\"] == 1].copy()\n",
    "\n",
    "# Map subreddits into 3 classes\n",
    "def map_class(subreddit):\n",
    "    if subreddit == \"anxiety\":\n",
    "        return \"anxiety\"\n",
    "    elif subreddit == \"ptsd\":\n",
    "        return \"ptsd\"\n",
    "    else:\n",
    "        return \"stress\"\n",
    "\n",
    "df[\"label\"] = df[\"subreddit\"].apply(map_class)\n",
    "\n",
    "# Add sub-source (original subreddit name) and source (Dataset_8)\n",
    "df[\"sub-source\"] = df[\"subreddit\"]\n",
    "df[\"source\"] = \"Dataset_8\"\n",
    "\n",
    "# Keep only relevant columns\n",
    "df_final = df[[\"text\", \"label\", \"sub-source\", \"source\"]]\n",
    "\n",
    "# ========= FUNCTION: get unique filename =========\n",
    "def get_unique_path(base_dir: Path, base_name: str) -> Path:\n",
    "    \"\"\"Return a unique path by adding _2, _3, etc. if needed.\"\"\"\n",
    "    out_path = base_dir / base_name\n",
    "    if not out_path.exists():\n",
    "        return out_path\n",
    "    # If exists, increment suffix\n",
    "    stem, ext = base_name.rsplit(\".\", 1)\n",
    "    i = 2\n",
    "    while True:\n",
    "        new_name = f\"{stem}_{i}.{ext}\"\n",
    "        out_path = base_dir / new_name\n",
    "        if not out_path.exists():\n",
    "            return out_path\n",
    "        i += 1\n",
    "\n",
    "# ========= SAVE SEPARATE FILES =========\n",
    "for class_name in df_final[\"label\"].unique():\n",
    "    subset = df_final[df_final[\"label\"] == class_name]\n",
    "    \n",
    "    # Start with class_dataset.csv\n",
    "    out_path = get_unique_path(warehouse_dir, f\"{class_name}_dataset.csv\")\n",
    "    \n",
    "    subset.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Saved {len(subset)} rows to {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312_xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
